{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> â€œMost of the world will make decisions by either guessing or using their gut. They will be either lucky or wrong.â€ ~ Suhail Doshi\n",
    "\n",
    "> â€œThere is nothing more deceptive than an obvious fact.â€ ~ (Sherlock Holmes) Arthur Conan Doyle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eda](https://mir-s3-cdn-cf.behance.net/project_modules/fs/3db83c97871397.5ecf4f75da3b3.png)  \n",
    "\n",
    "**Source:** [New Retail Big Data Situation Awareness Screen by Zoe Shen](https://www.behance.net/weiyi_1991c64f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is EDA?\n",
    "2. Questions To Explore\n",
    "3. Exploratory Data Analysis Stage\n",
    "    - A Bit of Data Prep\n",
    "    - Exploratory Stage\n",
    "4. Dashboard\n",
    "5. Takeaways / Reporting\n",
    "6. Blind Spots\n",
    "7. Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is EDA?\n",
    "\n",
    "![gloabl_emission](https://mir-s3-cdn-cf.behance.net/project_modules/1400_opt_1/a199d32434363.5635ff285dc8d.jpg)\n",
    "\n",
    "**Source:** [Paulina UrbaÅ„ska](https://www.behance.net/gallery/2434363/How-to-Reduce-CO2-Emission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA) is summarised in the name itself, it is an approach to data analysis where the goal is the exploration of the data and not necessarily hypothesis/model testing, although this can happen at this stage.\n",
    "\n",
    "[Wikepedia, along with all of its cited sources,](https://en.wikipedia.org/wiki/Exploratory_data_analysis) has a great definition which in turn was derived from the work of late John Tukey, a well-known statistician who is considered the creator of EDA as a concept and approach to data analysis.\n",
    "\n",
    "> In statistics, exploratory data analysis is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task. Exploratory data analysis was promoted by John Tukey to encourage statisticians to explore the data, and possibly formulate hypotheses that could lead to new data collection and experiments. EDA is different from initial data analysis (IDA), which focuses more narrowly on checking assumptions required for model fitting and hypothesis testing, and handling missing values and making transformations of variables as needed. EDA encompasses IDA.\n",
    "\n",
    "Characteristics of EDA\n",
    "- It allows us to spot further inconsistencies within the data after the preparation stage\n",
    "- It helps us ask questions that expose facts about the data we have\n",
    "- It allows us to see complex interactions within the data\n",
    "- The visualisations at this stage are not necessarily meant to be publication-ready but rather quick and dirty constructs to asnwer questions from a different perspectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Questions to Explore\n",
    "\n",
    "![funny_question](https://imgs.xkcd.com/comics/questions.png)  \n",
    "**Source:** [xkcd.com](https://xkcd.com/1256/)\n",
    "\n",
    "Here are the questions we will be exploring in this notebook. Before you head to the explanations, pause for a bit and think about how you would go about answering the following questions. Ask yourself, what kind of information would be most useful, which method/function and the like would be most appropriate to answer it? Should I visualise the answer as well?\n",
    "\n",
    "1. What does the distribution of our monetary columns look like?\n",
    "2. What's the difference in the average price charged by super hosts versus the regular ones?\n",
    "3. Do more bathrooms make a listing more expensive? ðŸ› | ðŸš½\n",
    "4. Do more rooms make a listing more expensive? \n",
    "5. Does the availability of more beds make a listing more expensive? ðŸ›\n",
    "6. Is there a noticeable price difference between room types offered by hosts? ðŸ˜\n",
    "7. Is there a noticeable price difference between room types that offer different quantities of beds in the listing? ðŸ› + ðŸ› != ðŸ›\n",
    "8. How important is it that our host is a verified one? âœðŸ½\n",
    "9. Should we care whether the listings asks for a license or not?\n",
    "10. Do we need Wifi, or can we be without it?\n",
    "11. Reviews! How important are they in our decision to buy or not to buy? ðŸ¤”\n",
    "12. Do we care about the cancellation policy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 A Bit of Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to install the following packages for this session. Once you install them, make sure you restart the notebook before you begin working on the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c pyviz holoviews panel bokeh -y\n",
    "# !jupyter labextension install @pyviz/jupyterlab_pyviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os, numpy as np\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import ColumnDataSource # similar to a pandas dataframe but specific for bokeh\n",
    "from bokeh.transform import dodge # a helpful tool for placing bar charts close to each other\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "\n",
    "\n",
    "import urllib # we will use this again to get more websites\n",
    "from PIL import Image # we will be looking at some Airbnb images\n",
    "import requests\n",
    "from io import BytesIO # for the images\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.float_format = '{:.4f}'.format # reduce numbers to 4 decimals\n",
    "hv.extension('bokeh') # holoviews will be using bokeh behind the scenes\n",
    "\n",
    "# this magic command helps us to not reload our session every time we install a new package\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first add a variable with the path to where all of our data lives at. If yours is different than the one below, make sure you change the variable below to the correct path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose to read in the cleaned dataset in whichever format you prefer, CSV or parquet. Uncomment the one you prefer and continue on.\n",
    "\n",
    "**Note:** If you were not able to save your file in the parquet format at the end of the previous notebook, make sure you go back and install the packages at the end of the notebook before you run it again. For now, go on with your CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv file\n",
    "# df = pd.read_csv(os.path.join(path, 'clean_csv', 'clean_airbnb.csv'), parse_dates=True)\n",
    "\n",
    "# parquet file\n",
    "df = pd.read_parquet(os.path.join(path, 'clean_parquet', 'clean_airbnb.parquet'))\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's quickly examine our data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step we are going to take is to create a column that represents the real price per stay. You might wonder, what do we mean by the real price per stay, so here is a quick explanation for that. Airbnb is an online marketplace with buyers (us) and sellers (the hosts), and in the same way we have our own specifications regarding where we would like to stay, the hosts might also have their own specifications in regards to whom they rent their places to. Here are some characteristics we need to pay attention to when creating our real price column.\n",
    "\n",
    "- The price is given per night\n",
    "- There is a cleaning fee which, if available, is not included in the price\n",
    "- The minimum amount of nights one can rent a listing for differs from country to country, and from listing to listing\n",
    "- There might be a security deposit we have to pay in advance\n",
    "\n",
    "The second step we are going to take is to start introducting our specifications to our analysis to narrow down the scope of our search. We will be traveling solo and even though our specifications will reflect this, each step of our process can also be extended to a much larger group of travelers.\n",
    "\n",
    "Let's begin by creating our `min_price_per_stay` column by multiplying the `price` column by the `minimum_nights` column and then adding the `cleaning_fee` and `security_deposit` columns. We will check the data types of our variables first to make sure these are all numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's make sure all of the columns we need are numerical\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `minimum_nights` column was not of a numerical type so we will convert to an integer column in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum_nights was not numerical so we will convert it to int32 with the .astype() method\n",
    "df['minimum_nights'] = df['minimum_nights'].astype(np.int32)\n",
    "df['minimum_nights'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now create our true cost variable\n",
    "df['min_price_per_stay'] = (df['price'] * df['minimum_nights']) + df['cleaning_fee'] + df['security_deposit']\n",
    "df['min_price_per_stay'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine the differences between the columns we just used, first throughout the entire dataset, and then split by country using the pandas `describe()` and `.groupby()` methods to see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns we want\n",
    "money_columns = ['price', 'cleaning_fee', 'security_deposit', 'minimum_nights', 'min_price_per_stay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe them to see what we have\n",
    "df[money_columns].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now look at the distribution of these variables per country\n",
    "money_measures = df.groupby('country')[money_columns].agg(['min', 'mean', 'median', 'max'])\n",
    "money_measures.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that should come to our attention is the fact that we have extremely low and high prices that, although we may have been able to deal with during the cleaning stage, they would have been difficult to spot without some analysis throughout that stage (and we would have peaked at the data too ðŸ‘€). Nonetheless, since we know our budget quite well, max 1,500 USD for 2 weeks, we will go ahead and filter out the listings that don't match that criterion. In addition, since we know (or assume that) it is very unlikely to see free listings (a price of 0) in Airbnb, we will get rid of any listing that costs less than 40 USD per stay, as this is a reasonable amount for a minimum per night (you can pick another value if you'd like).\n",
    "\n",
    "Let's create a max budget column by multiplying the `price` column by `14` and then adding the `cleaning_fee`. We will count on getting our deposit back so we will not include it in this particular variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['two_weeks_price'] = df['price'] * 14 + df['cleaning_fee']\n",
    "df['two_weeks_price'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `two_weeks_price` we will create a low price condition to filter out prices less then `x` (`x` can be anything you'd like). We will also create a minimum amount of nights condition as we are going on a 2 week trip, nothing more, nothing less. Lastly, we will need a budget condition for our `two_weeks_price` variable that filters out anything over 1,500 USD, and then we will filter our data using these conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our minimum amount\n",
    "low_price_condition = df['price'] > 40\n",
    "# our highest amount\n",
    "budget_condition = df['two_weeks_price'] <= 1500\n",
    "# minimum amount of nights cannot be greater than 2 weeks\n",
    "nights_min_condition = df['minimum_nights'] < 15\n",
    "# let's filter our data\n",
    "df_budget = df[low_price_condition & budget_condition & nights_min_condition].copy()\n",
    "df_budget.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should make sure there are no more `0` in the **min** index for the price column of our countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "money_measures = df_budget.groupby('country')[money_columns].agg(['min', 'mean', 'median', 'max'])\n",
    "money_measures.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Exploratory Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What does the distribution of our monetary columns look like? In other words, where are most of the prices at in relation to the most common vlues of our columns.\n",
    "\n",
    "For this question we could use the pandas plotting functionality first, and then move on to making a bit more informative plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plain pandas\n",
    "price_hist = df_budget['price'].hist(bins=40)\n",
    "price_hist;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use the library we just imported, holoviews, with NumPy and create a nicer looking histograms. But, what is a histogram anyways? [Acording to Wikipedia](https://en.wikipedia.org/wiki/Histogram) and their wonderful cited sources, a histogram is\n",
    "\n",
    "> an approximate representation of the distribution of numerical data. It was first introduced by Karl Pearson. To construct a histogram, the first step is to \"bin\" (or \"bucket\") the range of valuesâ€”that is, divide the entire range of values into a series of intervalsâ€”and then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins (intervals) must be adjacent and are often (but not required to be) of equal size.\n",
    "\n",
    "Awesome! How can we create one with holoviews and NumPy?\n",
    "\n",
    "1. Use `np.histogram()` to create 2 new arrays, one with the edges of the bins and another with the frequencies of the values within each edge. The function returns a tuple with 2 arrays so we will unpack the tuple into 2 variables.\n",
    "2. Pass your two variables as a tuple with your `edges` first and the `frequencies` second, to the `hv.Histogram` function.\n",
    "3. Evaluate your plot.\n",
    "\n",
    "Let's see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies, edges = np.histogram(df_budget['price'], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies[:5] # first array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[:5] # second array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Histogram((edges, frequencies)) # our dataviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be great if we could see all columns in one visualisation and have a widget to pick which column we'd like to see. Let's create just that.\n",
    "\n",
    "First we will create a function that takes in a column, creates a numpy histogram based on the data and the column we have selected, and then create a holoviews histogram. Remember that `**kwargs` means any combination of key-value pairs that could be overwritten or added to a function. We will call our new function `load_currency`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_currency(column, **kwargs):\n",
    "    frequencies, edges = np.histogram(df_budget[column], 50)\n",
    "    return hv.Histogram((frequencies, edges)).opts(framewise=True, tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_columns = ['price', 'cleaning_fee', 'security_deposit', 'minimum_nights', 'min_price_per_stay', 'two_weeks_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then use holoviews `DynamicMap` function as it allows us to map functions to the data to make interactive charts. The first argument is the plain function we just created and the second is the key dimension where the interactivity is coming from. In our case, this is our list of currency columns which will now be in a dropdown box for us to pick and choose. We will assign our new object to a variable called `dmap` and finish our visualisation by adding some options to the figure, mainly, height and width. The last step is to tell holoviews where these columns are coming from using the `.redim.values()` method. Note that `Money_Cols` is a name we came up with for the widget but it can be anything we'd like. All we need to do is to make sure that we use the same name for our kdims argument.\n",
    "\n",
    "**Note:** You could add more numerical variables to the list above and visualize even more histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = hv.DynamicMap(load_currency, kdims='Money_Cols').redim.values(Money_Cols=money_columns)\n",
    "dmap.opts(height=600, width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's an awesome visualisation and it allows us to evaluate the dispersion within our monetary columns more clearly. See if you can tweak the function and other parameters to come up with another cool visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the difference in the average price charged by super hosts versus the regular ones? What would be the difference if we were to split it by country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_super_diff = df_budget.pivot_table(\n",
    "    columns='host_is_superhost',\n",
    "    values='two_weeks_price',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "price_super_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_super_diff['t'] - price_super_diff['f']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a big difference at all. Let's look at the same measure but by country now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df_budget.pivot_table(\n",
    "    index='country',\n",
    "    columns='host_is_superhost',\n",
    "    values='two_weeks_price',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, even though there are some instances where the regular hosts are more expensive than the super hosts, for the most part, super hosts seem to have slightly higher prices for a two week stay than the regular ones. Let's go ahead and visualize this.\n",
    "\n",
    "We will first use [bokeh's ColumnDataSource object to create](https://docs.bokeh.org/en/latest/docs/user_guide/data.html) a bokeh-specific dataframe. This makes it easier for bokeh to convert any specification to JavaScript code before creating and showing the plot for us. In addition, it not only allows us to share data between different plots but there are also bokeh objects/glyphs/models that will only interact with data coming from a `ColumnDataSource` frame. To use it we can pass in the full dataset or specify the pieces of a dataset we will need using a dictionary or a similar object. We will use the dictionary to reassign all of the pieces from our table above and add this to a variable called `source`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(dict(\n",
    "    countries=q1.index,\n",
    "    super_host=q1.t,\n",
    "    regular_host=q1.f\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a bar chart with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your figure\n",
    "p = figure(x_range=list(q1.index), # the names or numbers to be used in the x axis\n",
    "           plot_height=350,\n",
    "           title=\"Average Cost for a 2-week Stay per Country\",\n",
    "           toolbar_location=None, tools=\"\") # we won't be using any toolbars here but you can if you'd like\n",
    "\n",
    "p.vbar(x=dodge('countries', -0.15, range=p.x_range), # dodge helps us separate the bars\n",
    "       top='super_host', \n",
    "       width=0.25, # this is the width of the green bars\n",
    "       source=source, # the data\n",
    "       color=\"#A3BE8C\", legend_label=\"Super Host\")\n",
    "\n",
    "p.vbar(x=dodge('countries',  0.15,  range=p.x_range), # dodge helps us separate the bars\n",
    "       top='regular_host', width=0.25, source=source,\n",
    "       color=\"#5E81AC\", legend_label=\"Regular Host\")\n",
    "\n",
    "\n",
    "p.x_range.range_padding = 0.3 # the space from the range of countries to the edges of the figure\n",
    "p.xgrid.grid_line_color = None # bars from each country to the top\n",
    "p.legend.location = (320, 265) # play with these numbers and see where you can place the legend at\n",
    "p.legend.orientation = \"horizontal\" # items are next to each other in the legend\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem to be a big difference between the prices charged by super hosts and regular hosts among the countries we picked. Let's keep exploring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Do more bathrooms make a listing more expensive?\n",
    "\n",
    "To answer this question, let's first plot the distribution of prices among the bathrooms available per listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathrooms_group = df_budget.groupby('bathrooms')\n",
    "bathrooms_group['two_weeks_price'].mean().plot(kind='bar', rot=-70);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems as if listings with 7.5 bathrooms will give us the absolute best deal, right? Let's look at the frequencies of these listings first to see whether this is a true average of more than one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bathrooms_group['two_weeks_price'].agg(['count', 'min', 'mean', 'median', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In effect, this average is not what we were expecting, but, we can explore further and see what's up with the ones with a lot of bathrooms and a relatively low price. Remember our image function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_show(image_url):\n",
    "    return Image.open(BytesIO(requests.get(image_url).content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathroom_num = 9.5\n",
    "some_images = df_budget.loc[df_budget['bathrooms'] == bathroom_num, ['id', 'picture_url', 'two_weeks_price']]\n",
    "some_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(some_images.iloc[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay at least we know that we do not want to stay a place without a single bathroom, so we will remove observations without at least one bathroom and assign the resulting dataframe to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathroom_cond = df_budget['bathrooms'] < 1 # we have to have bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bath = df_budget[~bathroom_cond].copy()\n",
    "print(f\"We reduced our search space by {df_budget.shape[0] - df_bath.shape[0]} listings!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Do more rooms make a listing more expensive on average? or, put in other words, what is the difference between prices in a listing with 0 or a few bedrooms versus a listing with (say) more than 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_num_group = df_bath.groupby('bedrooms')['two_weeks_price'].agg(['count', 'min', 'mean', 'median', 'max'])\n",
    "room_num_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_num_group.iloc[:, 1:].plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_num_group['mean'].plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't really compare averages here as the amount beds available in our dataset differs drastically, but there's still something useful to be said though. Let's look at the sorted values in decreasing order to see if we can spot the lowest prices of all. We'll create a function that takes in a dataframe, a column name, and a number to display after it sorts the array. We will then use our function in a for loop to print all of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_n_show(series, col_to_sort, n_toshow):\n",
    "    print(series.sort_values(col_to_sort)[col_to_sort][:n_toshow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in room_num_group.columns:\n",
    "    print(f\"This is the {col} column\")\n",
    "    sort_n_show(room_num_group, col, 3)\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although 12 bedrooms seem to be the one with the overall lowest price (and the one that appears the most), we need to do some further digging to really be sure of any selection. Before we move on, let's have a look at our infamous cheap listing with 12 bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_budget.loc[df_budget['bedrooms'] == 12, 'picture_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(df_budget.loc[df_budget['bedrooms'] == 12, 'picture_url'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_budget.loc[df_budget['bedrooms'] == 12, 'description'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahhh! That makes sense now, the guest house is not necessarily commenting on a room per se but rather putting down information that belongs to both, the entire house and the rooms. Hence, this might be a bargain for such a low price. Let's keep exploring though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What about the beds? Do we care about the amount of beds available within our listing, and/or is there a price difference between having more, none, or just 1? In other words, does the availability of more beds make a listing more expensive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beds_group = df_bath.groupby('beds')['two_weeks_price'].agg(['count', 'min', 'mean', 'median', 'max'])\n",
    "beds_group.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beds_group['mean'].plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is very little variation within the minimum price of a listing regardless of the amount of beds available, the median and mean tell a different story. As shown in the table and image above, while the minimum prices vary drastically, the mean and median do seem to be capturing the most commmon prices for x number of beds available in a listing. The oddball here was the number 22. We don't necessarily want to stay in a room with 22 beds if we don't have to so let's see what the image of that listing has to offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_url = df_bath.loc[df_bath['beds'] == 22, 'picture_url'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(bed_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is the second time we see this listing with the super low price, and while it doesn't seem like that bad a deal to take, we'll continue exploring to see if we can find better offerings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Is there a noticeable price difference between room types offered by hosts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms = df_bath.groupby('room_type')['two_weeks_price'].agg(['count', 'min', 'mean', 'median', 'max'])\n",
    "rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roomba = rooms[['min', 'mean', 'median', 'max']].plot(kind='bar', rot=45)\n",
    "roomba;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that there are not that many differences between most of the prices per se but the n count differs drastically between room type, and the shared rooms seem to have the lowest price of all on average. Let's keep exploring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Is there a noticeable average price difference between room types that offer different quantities of beds?\n",
    "\n",
    "Let's create a dummy variable of three categories for no beds, 1 bed, or more beds. We will use a function alogside some if-else statements, and the apply it to every element in our beds column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_dummy(x):\n",
    "    if x == 1:\n",
    "        return \"One\"\n",
    "    elif x < 1:\n",
    "        return 'None'\n",
    "    else:\n",
    "        return \"More than One\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bath['beds_dummy'] = df_bath.loc[:, 'beds'].apply(get_a_dummy).copy() # applies a function to every element in a column\n",
    "df_bath['beds_dummy'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a slightly more complex groupby object and see how our `two_weeks_price` changes with our new categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_and_beds = df_bath.groupby(['room_type', 'beds_dummy'])['two_weeks_price'].agg(['count', 'min', 'mean', 'median', 'max'])\n",
    "rooms_and_beds.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want at least one bed, and because of this, we will filter out those with no beds whatsoever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beds = df_bath[df_bath['beds_dummy'] != 'None'].copy()\n",
    "print(f\"We reduced our search by {df_bath.shape[0] - df_beds.shape[0]} listings!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "How important is it that our host is a verified one? Should we stay with a host that has not been verified? Probably not, but let's see what we have in terms of prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beds.host_identity_verified.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beds.pivot_table(\n",
    "    index='host_identity_verified',\n",
    "    columns='host_is_superhost',\n",
    "    values='two_weeks_price',\n",
    "    aggfunc='count'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beds.pivot_table(\n",
    "    index='host_identity_verified',\n",
    "    columns='host_is_superhost',\n",
    "    values='two_weeks_price',\n",
    "    aggfunc='mean'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it even possible to be a super host without being verified first? Apparently one can, but the verified ones are still cheaper. Let's go ahead and remove the hosts that have not been verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verified = df_beds[df_beds['host_identity_verified'] == 't'].copy()\n",
    "print(f\"We reduced our search by {df_beds.shape[0] - df_verified.shape[0]} listings!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Should we care whether the listings asks for a license or not?\n",
    "\n",
    "We don't have a license for either of this countries and your intructor, personally, does not have one at all (although he is a great driver nontheless ðŸ˜Ž + ðŸš— = ðŸ™ŒðŸ¼), but that does not mean we should get rid of the ones that require one since we technically don't know whether they mean an ID or an actual license. In addition, we might be getting rid of a lot of obsevations that we would not want to get rid of in the first place. Let's examine this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verified.requires_license.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verified.pivot_table(\n",
    "    index='room_type',\n",
    "    columns='requires_license',\n",
    "    values=['two_weeks_price', 'cleaning_fee'],\n",
    "    aggfunc=['count', 'mean']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems upon first inspection the price for our stay is cheaper with hosts that don't require a lisence. Let's see the rest of the story by country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verified.pivot_table(\n",
    "    index='country',\n",
    "    columns='requires_license',\n",
    "    values='two_weeks_price',\n",
    "    aggfunc=['count', 'mean']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In effect, if we get rid of the listings that do require a lisence (which might be the hosts saying you need an ID), we would be getting rid of all listings in Japan and we don't want that to happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Do we need Wifi, or can we be without it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wifi_yes = df_verified.amenities.str.contains('Wifi', case=False)\n",
    "wifi_yes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verified.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't have service and would hate to miss any important information regarding any activity we might have scheduled ahead of time. Because of this, we will have to take out the places that do not include Wifi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wifi = df_verified[wifi_yes].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Reviews! How important are they in our decision to rent or not to rent? ðŸ¤”\n",
    "\n",
    "Let's look at the distribution first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wifi['number_of_reviews'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review columns are informative but we need to make sure there are no reviews equal to 0 before we examine the next ones. That way we can actually explore them.\n",
    "\n",
    "Let's extract the reviews columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_cols = [col for col in list(df_wifi.columns) if 'review_scores' in col]\n",
    "review_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_condition = df_wifi['number_of_reviews'] != 0 # condition for no reviews\n",
    "yes_reviews = df_wifi.loc[reviews_condition].copy() # dataset with reviews\n",
    "no_reviews = df_wifi.loc[~reviews_condition].copy() # dataset without reviews\n",
    "yes_reviews['number_of_reviews'].describe(), no_reviews['number_of_reviews'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_reviews[review_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_reviews.groupby(['country', 'room_type'])[review_cols].mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs_price = sns.scatterplot(x='review_scores_rating', y='two_weeks_price', data=yes_reviews)\n",
    "revs_price;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the story changes when we split by room. We know we don't want to spend a fortune with this trip, but we are also aware that a bad pick could be detrimental to our stay. So, since we rather err on the cautious side, let's pick a cut off point for the reviews that makes sense to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = yes_reviews['review_scores_cleanliness'] > 8.5\n",
    "rating = yes_reviews['review_scores_rating'] > 85\n",
    "value = yes_reviews['review_scores_value'] > 8\n",
    "accuracy = yes_reviews['review_scores_accuracy'] > 9\n",
    "checkin = yes_reviews['review_scores_checkin'] > 7.5\n",
    "comms = yes_reviews['review_scores_communication'] > 8\n",
    "location = yes_reviews['review_scores_location'] > 8\n",
    "rating.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revs = yes_reviews.loc[clean & rating & value & accuracy & checkin & comms & location].copy()\n",
    "df_revs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revs.country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Do we care about the cancellation policy?\n",
    "\n",
    "Since it is an expensive trip, it is important to at least account for last minute emergencies and be sure that we can recuperate at least some of our money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revs.cancellation_policy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revs.cancellation_policy.value_counts().plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_strict = df_revs['cancellation_policy'] != 'super_strict_30'\n",
    "super_less_strict = df_revs['cancellation_policy'] != 'strict_14_with_grace_period'\n",
    "df_cancellation = df_revs.loc[super_strict & super_less_strict].copy()\n",
    "df_cancellation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since emergencies don't happen 14 days in advance, maybe, we will got rid of the two very strict cancellation policies and are down to about 1000 listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancellation.country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "What is the average price difference between getting a listing that can be booked instantly vs one that we cannot book it instantly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancellation.instant_bookable.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancellation.pivot_table(\n",
    "    index='country',\n",
    "    columns='instant_bookable',\n",
    "    values=money_columns,\n",
    "    aggfunc=['count', 'mean']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prices don't seem to be too one-sided when it comes to the speed at which one can book the listing, because of this, we will not worry about this measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "What is the price difference between listings that charge a security deposit vs those that don't?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the count difference first\n",
    "deposit = df_cancellation['security_deposit'] == 0\n",
    "print(f\"Require a deposit - {df_cancellation.loc[~deposit, 'security_deposit'].count()}\")\n",
    "print(f\"Does not require a deposit - {df_cancellation.loc[deposit, 'security_deposit'].count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancellation[~deposit].pivot_table(\n",
    "    index='country',\n",
    "    columns='room_type',\n",
    "    values=['two_weeks_price', 'security_deposit'],\n",
    "    aggfunc='mean'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the average security deposit fee varies drastically and Belgium seems to be the country with the highest deposit fee on average. Prices per country don't seem to vary much in Entire home/apt but they do vary a bit in a Private room."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "What is the price variation between the property types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancellation.pivot_table(\n",
    "    index='property_type',\n",
    "    values='two_weeks_price',\n",
    "    aggfunc=['count', 'mean']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Come up with 5 questions to help you narrow the search to at most 100 listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now go over several of the many ways in which we can create a dashboard in Python. We will use the library panel for this. Here is the description of Panel from its website,\n",
    "\n",
    "> Panel is an open-source Python library that lets you create custom interactive web apps and dashboards by connecting user-defined widgets to plots, images, tables, or text. ~ [HoloViz Team](https://panel.holoviz.org/index.html)\n",
    "\n",
    "What is a dashboard anyways?\n",
    "\n",
    "- A dashboard is a tool for summarizing critical or general information about a multitude of things that involve data\n",
    "- In business dashboards are used as graphical user interfaces to show the performance of a company from different angles\n",
    "- At a research center or market research firm, dashboards are used to explore data interactively\n",
    "- Dashboards display important statistics found in a dataset\n",
    "- Dashboards are used to enhance the viewers experience and ability to see more than one piece of information at a time\n",
    "\n",
    "In the words of data visualisation expert, [Steven Few](http://www.stephen-few.com/)\n",
    "\n",
    "> \"A dashboard is a visual display of the most important information needed to achieve one or more objectives; consolidated and arranged on a single screen so the information can be monitored at glance.â€\n",
    "\n",
    "Now that we now what a dashboard is, let's talk about how to build one with Python.\n",
    "\n",
    "- Load your libraries\n",
    "- Load your data\n",
    "- Sketch out what you need to build\n",
    "- Select a type, interactive or static\n",
    "- Select the appropriate chart for the information you would like to display\n",
    "- Choose an appropriate color\n",
    "- If it is interactive, build a function that returns your visual as an object\n",
    "- If it is static assign your visual to a variable\n",
    "- Build the blocks/components of your dashboard into a shape that makes sense for you, e.g. rows, columns, both, none\n",
    "- the list goes on ...\n",
    "\n",
    "Let's import Panel and a few other functions we will need. A few things to note about Panel first\n",
    "\n",
    "1. Panel has 3 main components: **Pane, Widget, and Panel**\n",
    "2. Almost anything can go into a **Panel** (e.g. markdown, visualisations, images, tables, etc.)\n",
    "3. **Widgets** provide us with interactivity\n",
    "4. **Pane**'s can be any element, addition or subtraction for a Panel or dashboard\n",
    "5. The convention for importing Panel is `pn`\n",
    "6. `pn.extension()` allows us to build interactive objects in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "from bokeh.transform import factor_cmap, factor_mark\n",
    "from bokeh.palettes import brewer\n",
    "\n",
    "pn.extension() # setting panel extension from the start allows us to create interactive object in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the title of one of our dashboards. Note that we can write markdown text in a piece of string that will go into panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"# A Place to Stay\\nThis dashboard has information found in three places we wish to stay at during our next vacation: South Africa, Japan, and Belgium\"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use our two visualisations from earlier to create a small dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(pn.Column(text, p), pn.Spacer(width=25), dmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about what just happened.\n",
    "\n",
    "- `pn.Row()` allows us to pass in visualisations, plain or markdown text, and other Panel options row-wise\n",
    "- `pn.Column()` does the same as `pn.Row()` but column-wise\n",
    "- `pn.Spacer` allows us to put space in between our visualisations\n",
    "\n",
    "Let's create an informative plot. We will plot the price per night against the amount of bathrooms in our dataset, and split each point by the `room_type` column and increase the size of the plots by the amount of beds in that listing. In addition, because our prices vary drastically, we will transform our price variable to a logarithmic scale, this means that the prices will be in the scale of 10 to the power of 1, 2, 3, and so forth. The benefit of doing this is that it allows us to better observe variables that have values very spread out.\n",
    "\n",
    "**Note** that we are using a sample of our entire dataset from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_types = df.room_type.unique()\n",
    "MARKERS = ['hex', 'circle_x', 'triangle', 'square']  # you can pick any markers you want from bokeh\n",
    "colors = ['#5E81AC', '#EBCB8B', '#A3BE8C', '#B48EAD'] # these colors belong to Nord\n",
    "\n",
    "bottom_left = figure(title = \"Prices, Bathrooms, and Rooms\", \n",
    "                     x_axis_label='Bathrooms', \n",
    "                     y_axis_label='Price 4 Our Stay', \n",
    "                     y_axis_type=\"log\"\n",
    ")\n",
    "\n",
    "bottom_left.scatter(y=\"price\", \n",
    "                    x=\"bathrooms\", \n",
    "                    source=df.sample(2000), \n",
    "                    legend_field=\"room_type\", # our legend will have our 4 room types\n",
    "                    fill_alpha=0.5, # the points will be a bit transparent\n",
    "                    size='beds', # they points size will increase by the amount of beds available in that listing\n",
    "                    marker=factor_mark('room_type', MARKERS, listings_types), # we map the markers to the room types\n",
    "                    color=factor_cmap('room_type', colors, listings_types) # we map the colors to the room types\n",
    ")\n",
    "\n",
    "show(bottom_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now proceed to create a sankey diagram with part of the process we have followed so far in the EDA stage. A Sankey diagram is an acyclical flow chart where the width of a line represents the proprotion of the source (e.g. a characteristic of feature in our data) to the target (e.g. the next characteristic or feature we mapped the source to), and using for the values whichever measure one wishes to show flowing through the diagram. In essence, to create a Sankey diagram we need the **source**, a **target**, and the **values**. The source and the target can be any 2 characteristics you want to see the flow to and from. To create these two, we will use groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges1 = df_bath.groupby(['room_type', 'host_is_superhost'])['two_weeks_price'].mean().reset_index()\n",
    "edges2 = df_bath.groupby(['host_is_superhost', 'country'])['two_weeks_price'].mean().reset_index()\n",
    "edges3 = df_bath.groupby(['country', 'cancellation_policy'])['two_weeks_price'].mean().reset_index()\n",
    "\n",
    "datasets = [edges1, edges2, edges4]\n",
    "\n",
    "for dt in datasets:\n",
    "    dt.columns = ['source', 'target', 'value']\n",
    "\n",
    "edges = pd.concat(datasets, axis=0)\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey = hv.Sankey(edges, label='Progression of Analysis')\n",
    "sankey.opts(label_position='left', edge_color='target', node_color='index', cmap='tab20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "See if you can add more layers to our sankey diagram and add it back into the dashboard(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"MPG by Cylinders and Data Source, Colored by Cylinders\"\n",
    "boxwhisker = hv.BoxWhisker(df_bath.sample(2000), 'room_type', 'beds', label=title)\n",
    "boxwhisker.opts(show_legend=False, width=600, box_fill_color=dim('room_type').str(), cmap='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png = pn.panel('https://www.clicdata.com/wp-content/uploads/2019/07/blog-difference-bi-dataviz-data-analytics.png', width=400, height=125)\n",
    "\n",
    "png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gspec = pn.GridSpec(sizing_mode='stretch_both', max_height=800)\n",
    "\n",
    "gspec[0, :3] = pn.Spacer(background='#88C0D0')\n",
    "gspec[1, 0] = png\n",
    "gspec[2, 0] = text\n",
    "gspec[1:3, 1:3] = boxwhisker\n",
    "gspec[3:5, 0] = bottom_left\n",
    "gspec[3:5, 1:3] = sankey\n",
    "# gspec[4:5, 2] = pn.Column(\n",
    "#     pn.widgets.FloatSlider(),\n",
    "#     pn.widgets.ColorPicker(),\n",
    "#     pn.widgets.Toggle(name='Toggle Me!'))\n",
    "\n",
    "gspec#.save('testing_dashboard.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_columns = ['price', 'cleaning_fee', 'security_deposit', 'min_price_per_stay', 'two_weeks_price']\n",
    "some_features = ['bathrooms', 'bedrooms', 'beds', 'accommodates', 'guests_included']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pn.widgets.Select(value='bathrooms', options=some_features, name='x')\n",
    "y = pn.widgets.Select(value='price', options=money_columns, name='y')\n",
    "\n",
    "\n",
    "@pn.depends(y.param.value, x.param.value)\n",
    "def make_pbr_plot(y, x, **kwargs):\n",
    "    \n",
    "    listings_types = ['Entire home/apt', 'Private room', 'Hotel room', 'Shared room']\n",
    "    MARKERS = ['hex', 'circle_x', 'triangle', 'square']\n",
    "    colors = ['#5E81AC', '#EBCB8B', '#A3BE8C', '#B48EAD']\n",
    "    \n",
    "    fig = figure(title = f\"{y.title()}, {x.title()}, and Rooms\", \n",
    "                 x_axis_label=f'{x.title()}', \n",
    "                 y_axis_label=f'{y.title()} 4 Our Stay', \n",
    "                 y_axis_type=\"log\")\n",
    "    \n",
    "    fig.scatter(y=y, x=x, source=df.sample(2000), legend_field=\"room_type\", fill_alpha=0.5, size='beds',\n",
    "          marker=factor_mark('room_type', MARKERS, listings_types),\n",
    "          color=factor_cmap('room_type', colors, listings_types))\n",
    "\n",
    "    return fig\n",
    "\n",
    "@pn.depends(x.param.value)\n",
    "def cat_whiskers(x, **kwargs):\n",
    "    title = f\"Rooms and {x.title()} distribution\"\n",
    "    boxwhisker = hv.BoxWhisker(df.sample(2000), 'room_type', x, label=title)\n",
    "    boxwhisker.opts(show_legend=False, width=600, box_fill_color=dim('room_type').str(), cmap='Set1')\n",
    "    return boxwhisker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = pn.interact(make_pbr_plot, x=some_features, y=money_columns)\n",
    "\n",
    "pn.Row(pn.Column('## MPG Explorer', layout[0]), layout[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_1 = pn.Row(\n",
    "    pn.Column('## Vars Explorer', x, y, pn.Spacer(width=25), cat_whiskers), pn.Spacer(width=25),\n",
    "    make_pbr_plot)\n",
    "\n",
    "pn.Tabs(('analysis', child_1), ('process', sankey))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Takeaways / Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Blind Spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
